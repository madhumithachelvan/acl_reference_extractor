{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97dae8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f707e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_acl_references(pdf_path, footer_margin=50, header_margin=50, debug=False):\n",
    "    \"\"\"\n",
    "    Extract references from an ACL format research paper PDF.\n",
    "    Uses line-level bbox x-coordinates to detect indentation.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        footer_margin: Height of footer area to ignore (default 50)\n",
    "        header_margin: Height of header area to ignore (default 50)\n",
    "        debug: If True, print diagnostic information\n",
    "        \n",
    "    Returns:\n",
    "        List of reference strings in order\n",
    "    \"\"\"\n",
    "    references = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Find References section\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    \n",
    "    ref_pattern = r'\\n\\s*(References|REFERENCES|Bibliography)\\s*\\n'\n",
    "    match = re.search(ref_pattern, full_text)\n",
    "    \n",
    "    if not match:\n",
    "        print(\"Could not find References section\")\n",
    "        doc.close()\n",
    "        return references\n",
    "    \n",
    "    ref_start_char = match.end()\n",
    "    current_char = 0\n",
    "    ref_start_page = 0\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page_text = doc[page_num].get_text()\n",
    "        if current_char + len(page_text) >= ref_start_char:\n",
    "            ref_start_page = page_num\n",
    "            break\n",
    "        current_char += len(page_text)\n",
    "    \n",
    "    # Extract lines with their bboxes\n",
    "    all_lines = []  # Store (page_num, column, y_pos, x_pos, text)\n",
    "    \n",
    "    for page_num in range(ref_start_page, len(doc)):\n",
    "        page = doc[page_num]\n",
    "        width = page.rect.width\n",
    "        height = page.rect.height\n",
    "        mid_x = width / 2\n",
    "        \n",
    "        clip = +page.rect\n",
    "        clip.y1 -= footer_margin\n",
    "        clip.y0 += header_margin\n",
    "        \n",
    "        blocks = page.get_text(\"dict\", flags=fitz.TEXTFLAGS_TEXT, clip=clip)[\"blocks\"]\n",
    "        \n",
    "        for block in blocks:\n",
    "            if block[\"type\"] == 0:  \n",
    "                block_bbox = block[\"bbox\"]\n",
    "                block_center_x = (block_bbox[0] + block_bbox[2]) / 2\n",
    "                column = 0 if block_center_x < mid_x else 1\n",
    "                \n",
    "                for line in block[\"lines\"]:\n",
    "                    line_bbox = line[\"bbox\"]\n",
    "                    line_text = \"\"\n",
    "                    for span in line[\"spans\"]:\n",
    "                        line_text += span[\"text\"]\n",
    "                    \n",
    "                    if line_text.strip():\n",
    "                        all_lines.append((page_num, column, line_bbox[1], line_bbox[0], line_text.strip()))\n",
    "    \n",
    "    # Sort lines: by page, then column, then y-position\n",
    "    all_lines.sort(key=lambda x: (x[0], x[1], x[2]))\n",
    "    \n",
    "    if not all_lines:\n",
    "        doc.close()\n",
    "        return references\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    column_min_x = defaultdict(list)\n",
    "    \n",
    "    for page_num, column, y_pos, x_pos, text in all_lines:\n",
    "        key = (page_num, column)\n",
    "        column_min_x[key].append(x_pos)\n",
    "        old_text = ''\n",
    "    \n",
    "    # Calculate minimum x for each (page, column)\n",
    "    min_x_map = {}\n",
    "    for key, x_positions in column_min_x.items():\n",
    "        min_x_map[key] = min(x_positions)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Min x-positions per (page, column):\")\n",
    "        for key, min_x in sorted(min_x_map.items()):\n",
    "            print(f\"  Page {key[0]}, Col {key[1]}: {min_x:.2f}\")\n",
    "    \n",
    "    # Parse references using indentation\n",
    "    tolerance = 3  # pixels - stricter tolerance\n",
    "    current_ref = \"\"\n",
    "    in_references = False\n",
    "    prev_was_A = False\n",
    "    ref_count = 0\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\nProcessing lines (showing first 50):\")\n",
    "    \n",
    "    page_list = []\n",
    "\n",
    "    for i, (page_num, column, y_pos, x_pos, text) in enumerate(all_lines):\n",
    "        if not in_references:\n",
    "            if re.search(r'(References|REFERENCES|Bibliography)', text):\n",
    "                in_references = True\n",
    "                if debug:\n",
    "                    print(f\"Found References at line {i}\")\n",
    "                continue\n",
    "        \n",
    "        if not in_references:\n",
    "            continue\n",
    "\n",
    "        # Check for appendix\n",
    "        if text.strip() == \"A\":\n",
    "            prev_was_A = True\n",
    "            if debug:\n",
    "                print(f\"Found 'A' at line {i}, checking next line...\")\n",
    "            continue\n",
    "        \n",
    "        if prev_was_A:\n",
    "            if debug:\n",
    "                print(f\"Appendix starts at line {i}: '{text}', stopping\")\n",
    "            break\n",
    "        \n",
    "        if re.match(r'^\\n*(?:A\\s+[A-Z])', text):\n",
    "            if page_num in page_list:\n",
    "                continue\n",
    "            if debug:\n",
    "                print(f\"Found Appendix at line {i}, stopping\")\n",
    "            break\n",
    "        \n",
    "        page_list.append(page_num)\n",
    "\n",
    "        # Determine if this is a new reference based on indentation\n",
    "        key = (page_num, column)\n",
    "        min_x = min_x_map.get(key, x_pos)\n",
    "        x_diff = x_pos - min_x\n",
    "        if column == 0:\n",
    "            tolerance = 3\n",
    "        elif column == 1:\n",
    "            tolerance = 15\n",
    "        is_new_ref = abs(x_diff) <= tolerance\n",
    "        \n",
    "        if debug and in_references and text.isnumeric():\n",
    "            print(f\"  [{i}] P{page_num}C{column} x={x_pos:.1f} min={min_x:.1f} diff={x_diff:.1f} {'NEW' if is_new_ref else 'CONT'}: {text[:60]}\")\n",
    "        \n",
    "        new_text = text\n",
    "        if is_new_ref:\n",
    "            # Save previous reference\n",
    "            if text.isnumeric():\n",
    "                continue\n",
    "            if current_ref:\n",
    "                references.append(current_ref.strip())\n",
    "                ref_count += 1\n",
    "            # Start new reference\n",
    "            current_ref = new_text.strip('-')\n",
    "        else:\n",
    "            # Continuation line\n",
    "            if current_ref:\n",
    "                if old_text[-1] == '-':\n",
    "                    current_ref += new_text.strip('-')\n",
    "                else:\n",
    "                    current_ref += \" \" + new_text.strip('-')\n",
    "            else:\n",
    "                current_ref = new_text.strip('-')\n",
    "        \n",
    "        prev_was_A = False\n",
    "        old_text = text\n",
    "    \n",
    "    if current_ref:\n",
    "        references.append(current_ref.strip())\n",
    "        ref_count += 1\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\nTotal references found: {ref_count}\")\n",
    "    \n",
    "    doc.close()\n",
    "    return references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda625ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def references_dict(references):\n",
    "    \"\"\" \n",
    "    Store each reference in a dataframe\n",
    "\n",
    "    Args:   \n",
    "        List of reference strings in order\n",
    "    Returns: \n",
    "        Dataframe of authors, year, title, venue \n",
    "        and DOI from each reference\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    ref_dict = {}\n",
    "\n",
    "    for i, ref in enumerate(references):\n",
    "        ref_dict[i]={}\n",
    "        count += 1\n",
    "        pattern_1 = '(^.+?)\\.\\s((?:19|20)\\d{2})\\.\\s(.*)'\n",
    "        obj = re.search(pattern_1, ref)\n",
    "        ref_dict[i]['authors'] = obj.group(1)       # Saves string of authors\n",
    "        ref_dict[i]['year'] = obj.group(2)          # Saves year\n",
    "        other = obj.group(3)\n",
    "\n",
    "        pattern_2 = r'^(.*?\\.)(\\s+.*)?$'\n",
    "        obj_2 = re.search(pattern_2, other)\n",
    "        ref_dict[i]['title'] = obj_2.group(1).strip('.')    # Saves title\n",
    "\n",
    "        if obj_2.group(2):\n",
    "            venue_det = obj_2.group(2).strip()\n",
    "            pattern_3 = re.compile('(?:In\\s+)?(?:Proceedings\\s+of\\s+)?'\n",
    "                                   '(?:the\\s+)?(.+?)(?:,\\s+(?=[A-Z][a-z]+,\\s+'\n",
    "                                   '[A-Z]|Virtual|Online|pages)|,\\s(abs/.+)?\\.|\\.$)')\n",
    "            obj_3 = re.search(pattern_3,venue_det)\n",
    "            # Saves venue and DOI\n",
    "            if obj_3.group(1):\n",
    "                ref_dict[i]['venue'] = obj_3.group(1)\n",
    "            else:\n",
    "                ref_dict[i]['venue'] = ''\n",
    "            if obj_3.group(2):\n",
    "                ref_dict[i]['doi'] = obj_3.group(2)\n",
    "            else:\n",
    "                ref_dict[i]['doi'] = ''\n",
    "        else:\n",
    "            ref_dict[i]['venue'] = ''\n",
    "            ref_dict[i]['doi'] = ''\n",
    "\n",
    "        # print('-----')\n",
    "        if count == 20:\n",
    "            break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(ref_dict,orient='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d31c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify PDF location and name as necessary\n",
    "pdf_loc = 'papers/'\n",
    "pdf_name = 'ACL_paper.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "395f446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = extract_acl_references(\n",
    "    pdf_loc+pdf_name,\n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b653a660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthropic</td>\n",
       "      <td>2024</td>\n",
       "      <td>Claude 3.7 system card</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Training a helpful and harmless assistant with...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>abs/2204.05862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marta R. Costa-jussà, Pierre Andrews, Eric Mic...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Multilingual holistic bias: Extending descript...</td>\n",
       "      <td>2023 Conference on Empirical Methods in Natura...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Dang, Shivalika Singh, Daniel D’souza, Ar...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aya expanse: Combining research breakthroughs ...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>abs/2412.04261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jwala Dhamala, Tony Sun, Varun Kumar, Satyapri...</td>\n",
       "      <td>2021</td>\n",
       "      <td>BOLD: dataset and metrics for measuring biases...</td>\n",
       "      <td>FAccT ’21: 2021 ACM Conference on Fairness, Ac...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Maxwell Forbes, Jena D. Hwang, Vered Shwartz, ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Social chemistry 101: Learning to reason about...</td>\n",
       "      <td>2020 Conference on Empirical Methods in Natura...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samuel Gehman, Suchin Gururangan, Maarten Sap,...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Realtoxicityprompts: Evaluating neural toxic d...</td>\n",
       "      <td>Findings of the Association for Computational ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naman Goyal, Cynthia Gao, Vishrav Chaudhary, P...</td>\n",
       "      <td>2022</td>\n",
       "      <td>The flores-101 evaluation benchmark for low-re...</td>\n",
       "      <td>Trans. Assoc. Comput. Linguistics, 10:522–538</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dan Hendrycks, Collin Burns, Steven Basart, An...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Aligning AI with shared human values</td>\n",
       "      <td>9th International Conference on Learning Repre...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yue Huang, Qihui Zhang, Philip S. Yu, and Lich...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Trustgpt: A benchmark for trustworthy and resp...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>abs/2306.11507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Gpt-4o system card</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>abs/2410.21276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zachary Kenton, Tom Everitt, Laura Weidinger, ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Alignment of language agents</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>abs/2103.14659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jiyoung Lee, Minwoo Kim, Seungho Kim, Junghwan...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Kornat: LLM alignment benchmark for korean soc...</td>\n",
       "      <td>Findings of the Association for Computational ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Stephanie Lin, Jacob Hilton, and Owain Evans</td>\n",
       "      <td>2022</td>\n",
       "      <td>Truthfulqa: Measuring how models mimic human f...</td>\n",
       "      <td>60th Annual Meeting of the Association for Com...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2024</td>\n",
       "      <td>Llama 3.2 connect 2024: Vision at the edge on ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almei...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Training language models to follow instruction...</td>\n",
       "      <td>Advances in Neural Information Processing Syst...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yurii Paniv, Dmytro Chaplynskyi, Nikita Trynus...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Setting up the data printer with improved Engl...</td>\n",
       "      <td>Third Ukrainian Natural Language Processing Wo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Morgane Rivière, Shreya Pathak, Pier Giuseppe ...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Gemma 2: Improving open language models at a p...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>abs/2408.00118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sergey Rodionov, Zarathustra Amadeus Goertzel,...</td>\n",
       "      <td>2023</td>\n",
       "      <td>An evaluation of GPT-4 on the ETHICS dataset</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>abs/2309.10492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Aman Saini, Artem Chernodub, Vipul Raheja, and...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Spivavtor: An instruction tuned Ukrainian text...</td>\n",
       "      <td>Third Ukrainian Natural Language Processing Wo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              authors  year  \\\n",
       "0                                           Anthropic  2024   \n",
       "1   Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda ...  2022   \n",
       "2   Marta R. Costa-jussà, Pierre Andrews, Eric Mic...  2023   \n",
       "3   John Dang, Shivalika Singh, Daniel D’souza, Ar...  2024   \n",
       "4   Jwala Dhamala, Tony Sun, Varun Kumar, Satyapri...  2021   \n",
       "5   Maxwell Forbes, Jena D. Hwang, Vered Shwartz, ...  2020   \n",
       "6   Samuel Gehman, Suchin Gururangan, Maarten Sap,...  2020   \n",
       "7   Naman Goyal, Cynthia Gao, Vishrav Chaudhary, P...  2022   \n",
       "8   Dan Hendrycks, Collin Burns, Steven Basart, An...  2021   \n",
       "9   Yue Huang, Qihui Zhang, Philip S. Yu, and Lich...  2023   \n",
       "10  Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam...  2024   \n",
       "11  Zachary Kenton, Tom Everitt, Laura Weidinger, ...  2021   \n",
       "12  Jiyoung Lee, Minwoo Kim, Seungho Kim, Junghwan...  2024   \n",
       "13       Stephanie Lin, Jacob Hilton, and Owain Evans  2022   \n",
       "14                                            Meta AI  2024   \n",
       "15  Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almei...  2022   \n",
       "16  Yurii Paniv, Dmytro Chaplynskyi, Nikita Trynus...  2024   \n",
       "17  Morgane Rivière, Shreya Pathak, Pier Giuseppe ...  2024   \n",
       "18  Sergey Rodionov, Zarathustra Amadeus Goertzel,...  2023   \n",
       "19  Aman Saini, Artem Chernodub, Vipul Raheja, and...  2024   \n",
       "\n",
       "                                                title  \\\n",
       "0                              Claude 3.7 system card   \n",
       "1   Training a helpful and harmless assistant with...   \n",
       "2   Multilingual holistic bias: Extending descript...   \n",
       "3   Aya expanse: Combining research breakthroughs ...   \n",
       "4   BOLD: dataset and metrics for measuring biases...   \n",
       "5   Social chemistry 101: Learning to reason about...   \n",
       "6   Realtoxicityprompts: Evaluating neural toxic d...   \n",
       "7   The flores-101 evaluation benchmark for low-re...   \n",
       "8                Aligning AI with shared human values   \n",
       "9   Trustgpt: A benchmark for trustworthy and resp...   \n",
       "10                                 Gpt-4o system card   \n",
       "11                       Alignment of language agents   \n",
       "12  Kornat: LLM alignment benchmark for korean soc...   \n",
       "13  Truthfulqa: Measuring how models mimic human f...   \n",
       "14  Llama 3.2 connect 2024: Vision at the edge on ...   \n",
       "15  Training language models to follow instruction...   \n",
       "16  Setting up the data printer with improved Engl...   \n",
       "17  Gemma 2: Improving open language models at a p...   \n",
       "18       An evaluation of GPT-4 on the ETHICS dataset   \n",
       "19  Spivavtor: An instruction tuned Ukrainian text...   \n",
       "\n",
       "                                                venue             doi  \n",
       "0                                                                      \n",
       "1                                                CoRR  abs/2204.05862  \n",
       "2   2023 Conference on Empirical Methods in Natura...                  \n",
       "3                                                CoRR  abs/2412.04261  \n",
       "4   FAccT ’21: 2021 ACM Conference on Fairness, Ac...                  \n",
       "5   2020 Conference on Empirical Methods in Natura...                  \n",
       "6   Findings of the Association for Computational ...                  \n",
       "7       Trans. Assoc. Comput. Linguistics, 10:522–538                  \n",
       "8   9th International Conference on Learning Repre...                  \n",
       "9                                                CoRR  abs/2306.11507  \n",
       "10                                               CoRR  abs/2410.21276  \n",
       "11                                               CoRR  abs/2103.14659  \n",
       "12  Findings of the Association for Computational ...                  \n",
       "13  60th Annual Meeting of the Association for Com...                  \n",
       "14                                                                     \n",
       "15  Advances in Neural Information Processing Syst...                  \n",
       "16  Third Ukrainian Natural Language Processing Wo...                  \n",
       "17                                               CoRR  abs/2408.00118  \n",
       "18                                               CoRR  abs/2309.10492  \n",
       "19  Third Ukrainian Natural Language Processing Wo...                  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df = references_dict(refs)\n",
    "ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to txt file\n",
    "ref_df.to_csv(f\"{pdf_loc+pdf_name.strip('.pdf')}.txt\", sep='\\t', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
